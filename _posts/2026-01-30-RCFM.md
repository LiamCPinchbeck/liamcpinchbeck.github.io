---
title: "Tutorial on Flow Matching and Normalising Flows on Spheres and general Riemannian Manifolds"
date: 2026-01-30
permalink: /posts/2026/01/2026-01-30-RCFM/
tags:
- Variational Inference
- Simulation-Based Inference
- SBI
- VI
- Flow Matching
- Normalising Flows
header-includes:
  - \usepackage{amsmath}

---

In this post I'm going to go through Flow Matching on Riemannian manifolds. 
It sounds a bit esoteric but has wide applications when the parameters you want to fit have some geometric quality to them that can otherwise make them hard to model. (UNDER CONSTRUCTION)


# UNDER CONSTRUCTION UNDER CONSTRUCTION UNDER CONSTRUCTION UNDER CONSTRUCTION UNDER CONSTRUCTION UNDER CONSTRUCTION


---

## Resources

### Riemannian Flow Matching:

- ["Flow Matching Guide and Code" - Meta](https://arxiv.org/abs/2412.06264), arXiv: 2412.06264

- Chen & Lipman (2024) - "Riemannian Flow Matching on General Geometries"
- De Bortoli (2022) - "Riemannian Score-Based Generative Models"
- Lou et al. (2024) - "Discrete Copula Diffusion"


### Manifold Normalizing Flows:

- Rezende et al. (2020) - "Normalizing Flows on Tori and Spheres"
- Gemici et al. (2016) - "Normalizing Flows on Riemannian Manifolds"
- Falorsi et al. (2019) - "Exploiting the Intrinsic Geometry for Learning"
- Mathieu & Nickel (2020) - "Continuous Hierarchical Representations with Poincar√© Variational Auto-Encoders"
- Bose et al. (2020) - "Latent Variable Modelling with Hyperbolic Normalizing Flows"



### Diffusion and Score Models on Manifolds:

- De Bortoli et al. (2022) - "Diffusion Schr√∂dinger Bridge with Applications to Score-Based Generative Modeling"
- Huang et al. (2022) - "Riemannian Diffusion Models"
- Leach et al. (2022) - "Denoising Diffusion Probabilistic Models on SO(3) for Rotational Alignment"


### Mathematical Background

- Lee (2018) - "Introduction to Riemannian Manifolds" (textbook)
- Lee (2013) - "Introduction to Smooth Manifolds" (textbook)
- Do Carmo (1992) - "Riemannian Geometry" (textbook)
- Absil et al. (2008) - "Optimization Algorithms on Matrix Manifolds"
- Pennec (2006) - "Intrinsic Statistics on Riemannian Manifolds"

### Implementation Resources

- GeomStats library (Python - Riemannian geometry with autodiff)
- Zuko library (normalizing flows with manifold support)
- Geoopt (Riemannian optimization in PyTorch)
- TorchCFM (continuous flow matching, some manifold extensions)


## Table of Contents

### Part I: Why Manifolds Matter
#### 1. The Representation Problem

- 1.1 Failure modes of Euclidean representations for constrained data
- 1.2 Example: Sky localization with RA/Dec ‚Üí the pole singularity
- 1.3 Example: Rotations with Euler angles ‚Üí gimbal lock
- 1.4 Example: Molecular torsion angles ‚Üí periodic wraparound
- 1.5 The identifiability crisis: when your posterior collapses incorrectly
- 1.6 Why constraints and projections are not enough

#### 2. Data That Lives on Manifolds

- 2.1 Directional data (wind, currents, orientations)
- 2.2 Gravitational wave sky positions (S¬≤)
- 2.3 Spin vectors and angular momentum
- 2.4 Molecular conformations (tori T‚Åø for dihedral angles)
- 2.5 3D rotations in robotics and computer vision (SO(3))
- 2.6 Poses and rigid transformations (SE(3))
- 2.7 Hierarchical embeddings (hyperbolic space H‚Åø)
- 2.8 Covariance matrices (SPD manifold)

#### 3. Geometric Inductive Biases

- 3.1 Why geometry matters for learning
- 3.2 Latent space geometry in VAEs
- 3.3 Matching the data manifold vs. embedding into Euclidean space
- 3.4 Computational efficiency from respecting structure
- 3.5 Sample efficiency and generalization


### Part II: Differential Geometry for Machine Learning
#### 4. Manifolds: The Basics

- 4.1 Intuition: surfaces that locally look like ‚Ñù‚Åø
- 4.2 Charts and atlases (why we need multiple coordinate systems)
- 4.3 Smooth structures
- 4.4 Embedded vs. abstract manifolds
- 4.5 Dimension and topology
- 4.6 Working example: the sphere S¬≤ with stereographic charts

#### 5. Tangent Spaces and Vector Fields

- 5.1 The tangent space T_xM at a point
- 5.2 Tangent bundle TM
- 5.3 Vector fields as sections of the tangent bundle
- 5.4 Pushforward and pullback
- 5.5 Lie bracket of vector fields
- 5.6 Computational perspective: representing tangent vectors

#### 6. Riemannian Metrics

- 6.1 Inner products on tangent spaces
- 6.2 The metric tensor g
- 6.3 Induced metrics from embeddings
- 6.4 Computing distances and lengths
- 6.5 Examples: canonical metrics on S¬≤, H‚Åø, SO(3)
- 6.6 Why the metric matters for flows

#### 7. Geodesics: Generalized Straight Lines

- 7.1 Shortest paths on manifolds
- 7.2 Geodesic equations (Christoffel symbols preview)
- 7.3 Existence and uniqueness (locally)
- 7.4 Computing geodesics in practice
- 7.5 Great circles on spheres
- 7.6 Geodesics in hyperbolic space
- 7.7 Why geodesics are the natural interpolants

#### 8. Exponential and Logarithmic Maps

- 8.1 The exponential map: exp_x : T_xM ‚Üí M
- 8.2 The logarithmic map: log_x : M ‚Üí T_xM
- 8.3 Normal coordinates
- 8.4 The injectivity radius (when things break down)
- 8.5 Computational formulas for common manifolds
- 8.6 Numerical considerations and stability
- 8.7 Why these maps are central to manifold learning

#### 9. Connections and Parallel Transport

- 9.1 The covariant derivative ‚àá
- 9.2 Christoffel symbols Œì‚Å±‚±º‚Çñ
- 9.3 Levi-Civita connection (the unique metric-compatible connection)
- 9.4 Parallel transport along curves
- 9.5 Why parallel transport matters for flows
- 9.6 Computational aspects

#### 10. Curvature (Intuition Only)

- 10.1 What curvature measures
- 10.2 Riemann curvature tensor (mention only)
- 10.3 Sectional, Ricci, and scalar curvature
- 10.4 Constant curvature spaces: sphere (+), Euclidean (0), hyperbolic (-)
- 10.5 Why we mostly ignore curvature in practice (but shouldn't)


### Part III: Probability on Manifolds
#### 11. Volume Forms and Integration

- 11.1 The Riemannian volume form
- 11.2 Integration on manifolds
- 11.3 Computing volumes
- 11.4 Example: volume of S‚Åø and H‚Åø

#### 12. Probability Distributions on Manifolds

- 12.1 Probability densities with respect to Riemannian volume
- 12.2 Pushforward measures
- 12.3 The uniform distribution on compact manifolds
- 12.4 Wrapped distributions (wrapping ‚Ñù‚Åø onto T‚Åø)
- 12.5 Projected distributions (projecting ‚Ñù‚Åø‚Å∫¬π onto S‚Åø)

#### 13. Common Base Distributions

- 13.1 Uniform on spheres S‚Åø
- 13.2 von Mises-Fisher (vMF) on spheres
- 13.3 Kent distribution on S¬≤
- 13.4 Wrapped Gaussian on circles and tori
- 13.5 Wrapped Cauchy on S¬π
- 13.6 Wrapped normal on hyperbolic space
- 13.7 Isotopic Gaussian on manifolds

#### 14. Statistics on Manifolds

- 14.1 Fr√©chet mean (intrinsic mean)
- 14.2 Geodesic variance
- 14.3 Principal geodesic analysis (PGA)
- 14.4 Covariance on tangent spaces
- 14.5 Maximum likelihood on manifolds


### Part IV: Change of Variables on Manifolds
#### 15. Review: Euclidean Change of Variables

- 15.1 The determinant Jacobian formula (quick recap from previous post)
- 15.2 Why we need to generalize this
- 15.3 Preview of the challenges

#### 16. The Manifold Change of Variables Formula

- 16.1 Pushforward of the volume form
- 16.2 The Riemannian Jacobian determinant
- 16.3 Working in local coordinates
- 16.4 Intrinsic formulation
- 16.5 Example: flow on S¬π
- 16.6 Example: flow on S¬≤ in stereographic coordinates

#### 17. Continuous Normalizing Flows on Manifolds

- 17.1 Vector fields generating flows on M
- 17.2 The instantaneous change of variables formula
- 17.3 Divergence on manifolds: div_g(v)
- 17.4 Computing the log-determinant
- 17.5 Tractable vs. intractable cases
- 17.6 Example: geodesic flows


### Part V: Classical Approaches to Manifold Flows
#### 18. Chart-Based Flows

- 18.1 Working in local coordinates
- 18.2 Applying Euclidean flows in charts
- 18.3 Transition functions and consistency
- 18.4 Problems with singularities and boundaries
- 18.5 When this approach works well

#### 19. Exponential Map Flows

- 19.1 Using exp_x to map tangent space to manifold
- 19.2 Euclidean flow in T_xM, then exponential map
- 19.3 Handling the injectivity radius
- 19.4 Computational cost

#### 20. Moser Flows and Volume Preservation

- 20.1 Volume-preserving diffeomorphisms
- 20.2 Moser's theorem
- 20.3 Applications to normalizing flows
- 20.4 Divergence-free vector fields

#### 21. Wrapped and Projected Flows

- 21.1 Wrapping ‚Ñù‚Åø flows onto T‚Åø
- 21.2 Projecting ‚Ñù‚Åø‚Å∫¬π flows onto S‚Åø
- 21.3 Issues with ambient space dimensionality
- 21.4 Loss of injectivity and information


### Part VI: Flow Matching on Manifolds
#### 22. Why Flow Matching on Manifolds?

- 22.1 Review: advantages of flow matching over CNFs (from previous post)
- 22.2 The manifold case: even more pronounced benefits
- 22.3 Avoiding expensive geodesic computations during training
- 22.4 Simplicity of regression objectives

#### 23. Geodesic Interpolation

- 23.1 The natural interpolant on Riemannian manifolds
- 23.2 Computing geodesics between two points
- 23.3 Geodesic interpolation: Œ≥(t; x‚ÇÄ, x‚ÇÅ) for t ‚àà [0,1]
- 23.4 The tangent vector along the geodesic
- 23.5 Using exp and log maps: Œ≥(t) = exp_{x‚ÇÄ}(t ¬∑ log_{x‚ÇÄ}(x‚ÇÅ))
- 23.6 Computational formulas for specific manifolds

#### 24. Conditional Probability Paths on Manifolds

- 24.1 Defining p_t(x | x‚ÇÅ) for x‚ÇÅ ~ p‚ÇÅ
- 24.2 Simple choices: geodesic + Euclidean-style noise
- 24.3 Wrapped Gaussian bridges
- 24.4 Riemannian Brownian bridges
- 24.5 The marginal path p_t(x)

#### 25. The Riemannian Flow Matching Objective

- 25.1 Conditional flow matching on manifolds
- 25.2 The regression target: vector field along geodesics
- 25.3 The CFM loss: L(Œ∏) = ùîº_{t,x‚ÇÅ,x_t} ||v_Œ∏(t, x_t) - u_t(x_t|x‚ÇÅ)||¬≤_g
- 25.4 Why this is still a simple regression problem
- 25.5 Connection to score matching on manifolds

#### 26. Training Riemannian Flow Matching Models

- 26.1 Sampling from p‚ÇÅ (data distribution)
- 26.2 Sampling from p‚ÇÄ (base distribution)
- 26.3 Computing the conditional geodesic interpolant
- 26.4 Computing the target vector field u_t
- 26.5 Training the neural vector field v_Œ∏
- 26.6 Practical considerations: batching, numerical stability

#### 27. Sampling and Inference

- 27.1 ODE integration on manifolds
- 27.2 Retraction and projection methods
- 27.3 Geodesic integrators
- 27.4 Adaptive stepping
- 27.5 Ensuring samples stay on the manifold
- 27.6 Probability flow ODE vs. stochastic sampling


### Part VII: Specific Geometries
#### 28. The Circle S¬π

- 28.1 Parameterization: angles Œ∏ ‚àà [0, 2œÄ)
- 28.2 Metric and geodesics
- 28.3 Exponential map: exp_Œ∏(v) = Œ∏ + v (mod 2œÄ)
- 28.4 Logarithmic map: log_Œ∏(œÜ) = shortest signed distance
- 28.5 Base distributions: wrapped normal, von Mises
- 28.6 Flow matching on S¬π: complete worked example
- 28.7 Implementation tricks: handling wraparound
- 28.8 Application: time-of-day, torsion angles

#### 29. The Sphere S¬≤

- 29.1 Embedding in ‚Ñù¬≥: x¬≤ + y¬≤ + z¬≤ = 1
- 29.2 Common parameterizations: lat/lon, spherical coordinates, stereographic
- 29.3 The round metric
- 29.4 Geodesics: great circles
- 29.5 Exponential map on S¬≤
- 29.6 Logarithmic map on S¬≤: careful with antipodal points
- 29.7 Tangent space projections
- 29.8 von Mises-Fisher base distribution
- 29.9 Flow matching on S¬≤: detailed implementation
- 29.10 Application: GW sky localization deep-dive
- 29.11 Handling the poles and coordinate singularities
- 29.12 Visualizing flows on the sphere

#### 30. Higher-Dimensional Spheres S‚Åø

- 30.1 Generalization to n dimensions
- 30.2 Exponential/logarithmic maps: same formulas
- 30.3 Computational tricks for high dimensions
- 30.4 Applications: embeddings, latent spaces

#### 31. Tori T‚Åø

- 31.1 Product of circles: T¬≤ = S¬π √ó S¬π
- 31.2 Flat metric (product of circle metrics)
- 31.3 Geodesics: straight lines with wrapping
- 31.4 Wrapped Gaussian as base distribution
- 31.5 Factorized vs. coupled flows
- 31.6 Application: molecular dihedral angles
- 31.7 Flow matching on T¬≤: complete example
- 31.8 Visualizing torus flows

#### 32. Hyperbolic Space H‚Åø

- 32.1 Motivation: hierarchies and trees
- 32.2 Models: Poincar√© ball, Poincar√© half-plane, hyperboloid
- 32.3 The hyperbolic metric (negative curvature)
- 32.4 Geodesics in the Poincar√© ball
- 32.5 Exponential and logarithmic maps
- 32.6 Wrapped normal distribution in H¬≤
- 32.7 Flow matching in hyperbolic space
- 32.8 Numerical stability: staying away from the boundary
- 32.9 Application: hierarchical embeddings, tree-structured data
- 32.10 Implementation with Geoopt

#### 33. Special Orthogonal Group SO(3)

- 33.1 3D rotations as a manifold
- 33.2 Parameterizations: rotation matrices, quaternions, axis-angle
- 33.3 The bi-invariant metric on SO(3)
- 33.4 Lie algebra so(3) and the exponential map
- 33.5 Logarithmic map for rotations
- 33.6 Geodesics on SO(3)
- 33.7 Uniform distribution on SO(3)
- 33.8 Flow matching for rotations
- 33.9 Application: protein backbone, molecular orientation
- 33.10 Handling quaternion double-cover

#### 34. Special Euclidean Group SE(3)

- 34.1 Rigid transformations: rotation + translation
- 34.2 Product manifold structure: SE(3) ‚âÖ SO(3) √ó ‚Ñù¬≥
- 34.3 Metrics on SE(3)
- 34.4 Exponential/logarithmic maps
- 34.5 Flow matching on SE(3)
- 34.6 Application: molecular conformations, robotics


### Part VIII: Neural Architectures for Manifold Flows
#### 35. Parameterizing Vector Fields on Manifolds

- 35.1 Input representation: intrinsic vs. extrinsic coordinates
- 35.2 Output representation: tangent vectors
- 35.3 Projection onto tangent spaces
- 35.4 Orthonormal frames and parallel transport
- 35.5 Using charts vs. staying intrinsic
- 35.6 Architecture choices: MLPs, attention, etc.

#### 36. Equivariance and Symmetries

- 36.1 Group actions on manifolds
- 36.2 Equivariant vector fields
- 36.3 Constructing equivariant architectures
- 36.4 Frame averaging as an alternative
- 36.5 Examples: SO(3)-equivariant flows, SE(3)-equivariant flows
- 36.6 When equivariance matters vs. when it doesn't

#### 37. Context Conditioning for Manifold Flows

- 37.1 Conditional generation on manifolds
- 37.2 Encoding context: neural networks for manifold data
- 37.3 Cross-attention mechanisms
- 37.4 Application: posterior estimation in SBI
- 37.5 Example: conditioning on GW time series for sky localization

#### 38. Handling Mixed Geometries

- 38.1 Product manifolds: M‚ÇÅ √ó M‚ÇÇ
- 38.2 Factorized flows vs. coupled flows
- 38.3 Metric structure on products
- 38.4 Example: (‚Ñù‚Å∫ √ó ‚Ñù‚Å∫) √ó S¬≤ for GW masses + sky position
- 38.5 When to couple and when to factorize


### Part IX: Training and Practical Considerations
#### 39. Implementation Details

- 39.1 Choosing the base distribution
- 39.2 Hyperparameters: learning rate, batch size
- 39.3 Time sampling strategies
- 39.4 Data augmentation on manifolds
- 39.5 Regularization techniques

#### 40. Numerical Stability

- 40.1 Avoiding coordinate singularities
- 40.2 Numerical precision in exp/log maps
- 40.3 Handling antipodal points on spheres
- 40.4 Boundary issues in hyperbolic space
- 40.5 Gradient clipping and normalization
- 40.6 Projection back onto the manifold

#### 41. ODE Integration on Manifolds

- 41.1 Euler method with projection/retraction
- 41.2 Runge-Kutta methods on manifolds
- 41.3 Geodesic integrators (exponential integrators)
- 41.4 Adaptive stepping
- 41.5 Error control and tolerance
- 41.6 Computational cost comparison

#### 42. Evaluation Metrics

- 42.1 Log-likelihood when tractable
- 42.2 Geodesic distance metrics
- 42.3 Fr√©chet Inception Distance on manifolds
- 42.4 Earth Mover's Distance on manifolds
- 42.5 Sample quality visualization
- 42.6 Coverage and diversity metrics

#### 43. Debugging Manifold Flows

- 43.1 Common failure modes
- 43.2 Samples leaving the manifold
- 43.3 Mode collapse on manifolds
- 43.4 Coordinate singularity artifacts
- 43.5 Poor mixing and multimodality
- 43.6 Visualization strategies for debugging


### Part X: Advanced Topics
#### 44. Optimal Transport on Manifolds

- 44.1 Wasserstein distance on Riemannian manifolds
- 44.2 Geodesic-based transport
- 44.3 Connections to flow matching
- 44.4 Entropic regularization

#### 45. Stochastic Interpolants Beyond Geodesics

- 45.1 Brownian motion on manifolds
- 45.2 Riemannian Langevin dynamics
- 45.3 Schr√∂dinger bridges on manifolds
- 45.4 When to use stochastic vs. deterministic paths

#### 46. Score-Based Models on Manifolds

- 46.1 Score functions on Riemannian manifolds
- 46.2 Score matching objective
- 46.3 Denoising score matching
- 46.4 Connection to flow matching
- 46.5 Diffusion models on manifolds

#### 47. Rectified Flows on Manifolds

- 47.1 Straightening probability paths
- 47.2 Reflow on Riemannian manifolds
- 47.3 Benefits and challenges

#### 48. Learning the Manifold Structure

- 48.1 When the manifold is unknown
- 48.2 Manifold learning + flows
- 48.3 Neural manifolds
- 48.4 Latent space geometry in VAEs

#### 49. Expressiveness and Limitations

- 49.1 Universal approximation on manifolds
- 49.2 Topological constraints (homotopy groups)
- 49.3 When flows cannot be injective
- 49.4 The role of base distribution support


### Part XI: Complete Implementations
#### 50. Tutorial: Flow Matching on S¬≤ from Scratch

- 50.1 Setting up the geometry (manual implementation)
- 50.2 Implementing exp_x and log_x for S¬≤
- 50.3 Creating the neural vector field network
- 50.4 Geodesic interpolation for training
- 50.5 Training loop with von Mises-Fisher base
- 50.6 ODE integration for sampling
- 50.7 Visualization on the sphere
- 50.8 Full PyTorch code

#### 51. Tutorial: Flow Matching on S¬≤ with GeomStats

- 51.1 Using GeomStats for geometry
- 51.2 Simplified implementation
- 51.3 Comparison with manual implementation
- 51.4 Performance considerations

#### 52. Tutorial: Conditional Flow Matching for GW Sky Localization

- 52.1 Problem setup: time series ‚Üí posterior on S¬≤
- 52.2 Encoder architecture for GW data
- 52.3 Context-conditioned vector field
- 52.4 Training on simulated GW events
- 52.5 Evaluation against MCMC/nested sampling
- 52.6 Handling ambiguities and multimodality
- 52.7 Complete working code

#### 53. Tutorial: Flow Matching on Hyperbolic Space H¬≤

- 53.1 Poincar√© ball model setup
- 53.2 Implementing hyperbolic exp/log with Geoopt
- 53.3 Wrapped normal base distribution
- 53.4 Neural vector field in hyperbolic space
- 53.5 Training and sampling
- 53.6 Visualization: Poincar√© disk plots
- 53.7 Application: hierarchical embeddings
- 53.8 Full implementation

#### 54. Tutorial: Flow Matching on SO(3)

- 54.1 Quaternion representation
- 54.2 Geodesics on SO(3)
- 54.3 Uniform base distribution
- 54.4 Training rotation flows
- 54.5 Sampling and visualization
- 54.6 Application example

#### 55. Tutorial: Mixed Geometry Flow (‚Ñù¬≤ √ó S¬≤)

- 55.1 Product manifold setup
- 55.2 Factorized vs. coupled architectures
- 55.3 Implementing product geodesics
- 55.4 Training on synthetic data
- 55.5 When coupling helps vs. hurts


### Part XII: Applications and Case Studies
#### 56. Gravitational Wave Parameter Estimation

- 56.1 The full parameter space: masses, spins, sky position, distance
- 56.2 Geometry: (‚Ñù‚Å∫)¬≤ √ó (S¬≤)¬≤ √ó S¬≤ √ó ‚Ñù‚Å∫
- 56.3 Dealing with the identifiability issues you've encountered
- 56.4 Why RA/Dec become uninformative for certain signals
- 56.5 Comparison with Dingo, RIFT, nested sampling
- 56.6 Computational speedup analysis
- 56.7 Uncertainty quantification on manifolds

#### 57. Molecular Conformational Sampling

- 57.1 Dihedral angles on T‚Åø
- 57.2 Backbone atoms on SE(3)
- 57.3 Joint modeling
- 57.4 Boltzmann distribution as target
- 57.5 Flow matching for equilibrium sampling

#### 58. Robotics: Motion Planning

- 58.1 Configuration spaces as manifolds
- 58.2 SE(3) for end-effector poses
- 58.3 Learning distributions over trajectories
- 58.4 Obstacle avoidance

#### 59. Computer Vision: Pose Estimation

- 59.1 Camera pose: SO(3) √ó ‚Ñù¬≥
- 59.2 Object orientation estimation
- 59.3 Uncertainty quantification

#### 60. Geospatial Data

- 60.1 Climate patterns on Earth's surface
- 60.2 Earthquake epicenter localization
- 60.3 Wind and ocean current directions


### Part XIII: Software Ecosystem
#### 61. GeomStats Deep Dive

- 61.1 Core abstractions: Manifold, Metric, Connection
- 61.2 Supported manifolds
- 61.3 Integration with PyTorch and JAX
- 61.4 Custom manifold implementation
- 61.5 Performance tips

#### 62. Geoopt for Optimization

- 62.1 Riemannian optimizers
- 62.2 Manifold parameters in neural networks
- 62.3 Use cases

#### 63. Building Custom Manifold Operations

- 63.1 When to use libraries vs. custom code
- 63.2 Implementing exp/log from scratch
- 63.3 Autodiff considerations
- 63.4 Testing numerical correctness

#### 64. Performance Optimization

- 64.1 Batching on manifolds
- 64.2 GPU acceleration
- 64.3 Caching geodesic computations
- 64.4 Vectorizing manifold operations
- 64.5 Memory efficiency


### Part XIV: Theory and Foundations
#### 65. Universal Approximation

- 65.1 Density of smooth maps on manifolds
- 65.2 Neural network approximation theorems
- 65.3 Expressiveness of manifold flows

#### 66. Topological Constraints

- 66.1 Homotopy groups and fundamental group
- 66.2 When flows cannot be global diffeomorphisms
- 66.3 Covering spaces
- 66.4 Example: flows on S¬π and winding number

#### 67. Curvature Effects (Going Deeper)

- 67.1 How curvature affects geodesics
- 67.2 Jacobi fields and conjugate points
- 67.3 Cut locus
- 67.4 Implications for flow matching

#### 68. Geometric Measure Theory

- 68.1 Hausdorff measure
- 68.2 Rectifiability
- 68.3 Disintegration of measures
- 68.4 Relevance to manifold learning


### Part XV: Frontiers and Open Problems
#### 69. Current Research Directions

- 69.1 Manifold flow matching with unknown geometry
- 69.2 Flows on infinite-dimensional manifolds
- 69.3 Discrete manifolds and graphs
- 69.4 Quotient manifolds and symmetry breaking
- 69.5 Learning with geometric constraints

#### 70. Open Problems

- 70.1 Optimal base distributions for different manifolds
- 70.2 Scaling to very high-dimensional manifolds
- 70.3 Better numerical integrators
- 70.4 Theoretical guarantees for manifold flow matching
- 70.5 Sample complexity analysis

#### 71. Connections to Other Fields

- 71.1 Information geometry
- 71.2 Symplectic geometry and Hamiltonian flows
- 71.3 Contact geometry
- 71.4 Geometric deep learning
- 71.5 Gauge theories and physics


### Part XVI: Practical Decision-Making Guide
#### 72. Choosing the Right Approach

- 72.1 Decision tree: when to use manifold flows
- 72.2 Euclidean + constraints vs. intrinsic manifold modeling
- 72.3 Computational cost-benefit analysis
- 72.4 When simple projections are enough
- 72.5 When you really need manifold structure

#### 73. Architecture Selection Guide

- 73.1 Matching architecture to manifold geometry
- 73.2 When to use equivariant networks
- 73.3 Coupling strategies for product manifolds
- 73.4 Base distribution selection heuristics

#### 74. Debugging Checklist

- 74.1 Systematic debugging workflow
- 74.2 Numerical issues: detection and fixes
- 74.3 Training issues: diagnosis and solutions
- 74.4 Sampling issues: what to check

#### 75. Production Deployment

- 75.1 Computational efficiency in production
- 75.2 Model compression for manifold flows
- 75.3 Uncertainty calibration
- 75.4 Monitoring and maintenance


### Appendices
#### A. Mathematical Reference

- A.1 Differential geometry glossary
- A.2 Useful identities and formulas
- A.3 Manifold cheat sheet with formulas

#### B. Computational Reference

- B.1 Exponential/logarithmic maps for all common manifolds
- B.2 Geodesic equations
- B.3 Christoffel symbols
- B.4 Volume forms

#### C. Code Snippets Library

- C.1 Core operations on S¬≤, S‚Åø, H‚Åø, SO(3), SE(3), T‚Åø
- C.2 Numerical integrators
- C.3 Visualization utilities
- C.4 Testing and validation code

#### D. Notation Guide

- D.1 Manifold notation conventions
- D.2 Index conventions (Einstein summation, etc.)
- D.3 Common symbols and their meanings

#### E. Further Reading by Topic

- E.1 Differential geometry textbooks
- E.2 Riemannian optimization
- E.3 Optimal transport
- E.4 Geometric deep learning
- E.5 Domain-specific applications