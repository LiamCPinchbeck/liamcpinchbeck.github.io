---
title: 'An introduction to Simulation-Based Inference with NRE'
date: 2025-08-14
permalink: /posts/2025/08/2025-08-14-SBI-w-NRE/
tags:
  - PyTorch
  - Variational Inference
  - Simulation Based Inference
  - NRE
header-includes:
   - \usepackage{amsmath}
---


In this post, I’ll attempt to give an introduction to simulation-based inference specifically delving into the method of NRE including rudimentary implementations. ***UNDER CONSTRUCTION***

---

## Resources

As usual, here are some of the resources I’m using as references for this post. Feel free to explore them directly if you want more information or if my explanations don’t quite click for you. I will highly recommend it for this particular post as I'm using it as motivation to learn about these methods myself in more detail.

- [A robust neural determination of the source-count distribution of the Fermi-LAT sky at high latitudes](https://arxiv.org/abs/2505.02906) by [Eckner](https://arxiv.org/search/astro-ph?searchtype=author&query=Eckner,+C) et al.
- [The frontier of simulation-based inference](https://arxiv.org/pdf/1911.01429) by [Kyle Cranmer](https://theoryandpractice.org/), [Johann Brehmer](https://johannbrehmer.github.io/) and [Gilles Louppe](https://glouppe.github.io/)
- [Recent Advances in Simulation-based Inference for Gravitational Wave Data Analysis](https://arxiv.org/abs/2507.11192) by [Bo Liang](https://www.researchgate.net/profile/Bo-Liang-34) and [He Wang](https://iphysresearch.github.io/-he.wang/author/he-wang-%E7%8E%8B%E8%B5%AB/)
    - Really recommend giving this a read, it's hard to find papers that discuss the general topics without getting into the weeds of the specific implementation that they are trying to advocate for or simply too vague.
- [Consistency Models for Scalable and Fast Simulation-Based Inference](https://proceedings.neurips.cc/paper_files/paper/2024/file/e58026e2b2929108e1bd24cbfa1c8e4b-Paper-Conference.pdf)
- [Missing data in amortized simulation-based neural posterior estimation](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1012184)
    - Only paper I've read that directly and nicely talks about using aggregator networks for variable dataset sizes
- [Likelihood-free MCMC with Amortized Approximate Ratio Estimators](https://arxiv.org/abs/1903.04057)
    - Specifically sections 2.2 and 3.1
- [Contrastive Neural Ratio Estimation for Simulation-based Inference](https://arxiv.org/pdf/2210.06170)
- [LAMPE - Neural Ratio Estimation Tutorial](https://lampe.readthedocs.io/stable/tutorials/nre.html)



---

## Table of Contents

- [Motivation](#motivation)
- [Core Idea](#core-idea-repeat-of-last-post)
- [Neural Ratio Estimation](#neural-ratio-estimation)
    - [A side note on final layer sigmoid](#a-side-note-about-using-sigmoid)
- [Rudimentary Implementations](#rudimentary-implementations)
    - [Binary Classifier Network](#binary-classifier-network)
    - [Per Event Level NRE](#per-event-rudimentary-implementation)
    - [Dataset Level NRE](#dataset-level-rudimentary-implementation)
- [Conclusion](#conclusion)


---


# Motivation

The TLDR of simulation-based-inference (SBI)[^lfi] is that you have a prior on some parameters $$\vec{\theta}$$ and a simulator $$g$$, which can give you realistic data $$\vec{x}=g(\vec{\theta})$$, and you utilise advances in machine learning to learn the likelihood or posterior for use in analysis without having to actually specify the likelihood directly[^lfi]. 

[^lfi]: Also equivalently known likelihood-free-inference (LFI), but I prefer the use of SBI as the analysis isn't "likelihood-free" per say but that you _learn_ the likelihood instead of providing it from the get-go.

The benefits of SBI include but are not limited to:
1. The _ability to handle large numbers of nuisance parameters_ (see above)
2. The user _does not have to specify the likelihood_ and allows direct inference if a realistic simulator already exists (e.g. climate modelling)
3. There have been a few works showing that _SBI methods can better handle highly non-gaussian and [highly-multi-modal]() relationships_ within probability distributions
4. _Amortised inference_, you can train a model to approximate the probabilities for a dataset and then re-use for other observations relatively trivially
5. Through the use of the simulators and neural networks involved, _SBI is generally easier to parallelise_
6. _Efficient exploration of parameter space_, through the fact that the simulator will often only output realistic data, the algorithms don't have to waste time in regions of the parameter space that don't lead to realistic data.

The ability to handle a large number of nuisance parameters is actually what sparked my interest in SBI through the paper [A robust neural determination of the source-count distribution of the Fermi-LAT sky at high latitudes](https://arxiv.org/abs/2505.02906) by [Eckner](https://arxiv.org/search/astro-ph?searchtype=author&query=Eckner,+C) et al. who used Nested Ratio Estimation (NRE, which I'll discuss later) to analyse data with a huge number of nuisance parameters introduced by an unknown source distribution in the gamma-ray sky.

I would recommend looking at [The frontier of simulation-based inference](https://arxiv.org/pdf/1911.01429) by [Kyle Cranmer](https://theoryandpractice.org/), [Johann Brehmer](https://johannbrehmer.github.io/) and [Gilles Louppe](https://glouppe.github.io/) and the references therein to check these claims out for yourself if you want.


And more recently, I came across this great paper by [Bo Liang](https://www.researchgate.net/profile/Bo-Liang-34) and [He Wang](https://iphysresearch.github.io/-he.wang/author/he-wang-%E7%8E%8B%E8%B5%AB/) called [Recent Advances in Simulation-based Inference for Gravitational Wave Data Analysis](https://arxiv.org/abs/2507.11192) that discusses the use of SBI within gravitational wave data analysis (in the title I know) but it also discusses some of the popular SBI methods in use as of writing. So, I thought I would try and touch on how each of them work in a little more detail than the paper allowed and try to make it a little more general, additionally showing some rudimentary implementations of some of them, with the end goal really being understanding the below figure (Fig. 1 from the paper).

<p>
    <div style="text-align: center;">
    <img 
        src="/files/BlogPostData/2025-08-sbi/model.png" 
        alt="Figure 1. from 'Recent Advances in Simulation-based Inference for Gravitational Wave Data Analysis' detailing various SBI methods"
        title="Figure 1. from 'Recent Advances in Simulation-based Inference for Gravitational Wave Data Analysis' detailing various SBI methods"
        style="width: 90%; height: auto; border-radius: 32px;">
        <figcaption> Fig.1 caption from Liang and Wang's paper - <em>"Overview of five SBI methods—NPE, NRE, NLE, FMPE, and CMPE—designed for efficient Bayesian parameter
estimation. Each method includes distinct training and inference stages. NPE trains a neural network to directly approximate the
posterior from simulated data. NRE and NLE estimate the likelihood ratio and likelihood function, respectively, and integrate with
MCMC for posterior sampling. FMPE uses an ODE solver guided by a neural network to characterize the parameter posterior.
CMPE fits a probability flow with a neural network to sample from posterior distributions. These approaches leverage neural
networks to approximate complex posteriors, providing a computationally efficient and flexible alternative to traditional Bayesian
inference methods." </em></figcaption>
    </div>
</p>


In my [last post](https://liamcpinchbeck.github.io/posts/2025/08/2025-08-11-SBI-w-NPE-NLE/) I went through Neural Posterior Estimation and Neural Likelihood Estimation, and in this post I'll attempt to go through a basic implmentation of Neural Ratio Estimation and in future posts Classifer-based Mutual Posterior Estimation and finally Flow Matching Posterior Estimation (rough order of how hard it will be to make rudimentary implementations).


# Core Idea (Repeat of last post)


First we assume that one has priors for the set of hyperparameters that theoretically influence the data of a given system. e.g.

$$\begin{align}
\vec{\theta}\sim \pi(\vec{\theta}),
\end{align}$$

where $$\vec{\theta}$$ is the set of hyperparameters we are interested in. And further assume (for now) that either: 
- the set of nuisance parameters $$\vec{\eta}$$ can be further sampled based on these values, 
- or that the two sets are independent.

Taking the stronger assumption of independence as it is often not restricting in practice,

$$\begin{align}
\vec{\theta}, \vec{\eta} \sim \pi(\vec{\theta})\pi(\vec{\eta}).
\end{align}$$

Denoting the simulator that takes in these values and outputs possible realisations of the data as $$g$$ then,

$$\begin{align}
\vec{x} \sim g(\vec{\theta}, \vec{\eta}).
\end{align}$$

This is in effect samples from the likelihood and with this we have samples from the joint probability distribution through Bayes' theorem with marginalisation over the nuisance parameters ,

$$\begin{align}
\vec{x}, \vec{\theta}, \vec{\eta} &\sim \mathcal{L}(\vec{x}\vert \vec{\theta}, \vec{\eta}) \pi(\vec{\theta})\pi(\vec{\eta}) \\
&= p(\vec{x}, \vec{\eta}, \vec{\theta} ),
\end{align}$$

assuming that we can robustly sample over the space of nuisance parameters, we can imagine simultaneously marginalising them out[^m] when generating the samples such that[^exp],

[^m]: in practice this just comes to throwing the samples of the nuisance parameters out
[^exp]: If you're unfamiliar with the notation $$\mathbb{E}_{\vec{\eta}\sim \pi(\vec{\eta}) }$$ denote the average over $$\vec{\eta}$$ using the probability distribution $$ \pi(\vec{\eta})$$ in the continuous case, which is most often assumed for these problems, $$\mathbb{E}_{\vec{\eta}\sim \pi(\vec{\eta}) }\left[f(\vec{\eta}) \right] = \int_{\vec{\eta}} d\left(\vec{\eta}\right) \pi(\vec{\eta}) f(\vec{\eta}) $$

$$\begin{align}
\vec{x}, \vec{\theta} &\sim \mathbb{E}_{\vec{\eta}\sim \pi(\vec{\eta}) } \left[\mathcal{L}(\vec{x}\vert \vec{\theta}, \vec{\eta}) \pi(\vec{\theta})\pi(\vec{\eta})\right] \\
&= \mathcal{L}(\vec{x} \vert \vec{\theta} )\pi(\vec{\theta}) \\
&= p(\vec{x}, \vec{\theta} ).
\end{align}$$

Now because we have these samples, we can try and approximate the various densities that are behind them, using variational approximations such as normalising flows, variational autoencoders, etc. And that's SBI, the different methods differ in specifically how they choose to model these densities (e.g. flow vs VAE) and importantly which densities they are actually trying to approximate. e.g. Neural Posterior Estimation directly models the posterior density $$p(\vec{\theta}\vert\vec{x})$$, while Neural Likelihood Estimation tries to model the likelihood $$\mathcal{L}(\vec{x}\vert \vec{\theta})$$ and then you use something like MCMC to obtain the posterior density $$p(\vec{\theta}\vert\vec{x})$$. 

Something a little different compared to the other methods in the list above, is _Neural Ratio Estimation_. The TLDR is that you train a binary classifier to distinguish between samples that came from the joint density $$\vec{x}, \vec{\theta} \sim p(\vec{x}, \vec{\theta})$$ and those that came from the marginals $$\vec{x}, \vec{\theta} \sim p(\vec{x})p(\vec{\theta})$$ or in essence when they are unrelated. Let's see how that works.


# Neural Ratio Estimation

Let's denote samples that came from the joint distribution as $$y=1$$, and those that came from independent marginals as $$y=0$$. 

We have our samples from the joint distribution, but how do we get samples from the marginals? Well the main characteristic of these samples is that they are unrelated. Presuming that our joint samples are representative, we can sample the same amount again $$\vec{x}_m, \vec{\theta}_m \sim p(\vec{x}, \vec{\theta})$$ with a subscript to denote which samples we're looking at. 

Now all that we want is to shuffle these samples, so that the $$\vec{x}_m$$ samples have no relation to the $$\vec{\theta}_m$$ samples. And by learning when the $$\vec{x}$$ is related to $$\vec{\theta}$$ we secretly learn the likelihood $$\mathcal{L}(\vec{x}\vert\vec{\theta})$$.

The key assumption of this method is that these samples are actually representative enough to make the classifier robust. Presuming that this is the case, then we can say, for some classifier $$f_\varphi$$ the optimal solution is that it represents the probability of a sample coming from one distribution or the other[^bcep]. In essence,

[^bcep]: [Likelihood-free Markov chain Monte Carlo with Amortized Approximate Ratio Estimators](https://arxiv.org/pdf/1903.04057) cover this in Appendix B if you wanted to double check this

$$\begin{align}
f_\varphi(\vec{x}_i, \vec{\theta}_i) = \frac{p(y=1\vert \vec{x}_i, \vec{\theta}_i)}{p(y=0\vert \vec{x}_i, \vec{\theta}_i) + p(y=1\vert \vec{x}_i, \vec{\theta}_i)}.
\end{align}$$

We're now going to do some algebraic manipulation which all we need to remember is Bayes' theorem,

$$\begin{align}
p(A\vert B) = \frac{p(B\vert A)p(A)}{p(B)}.
\end{align}$$

Doing as such presuming that the prior of a given sample coming from the joint density or the marginals is the same,

$$\begin{align}
f_\varphi(\vec{x}_i, \vec{\theta}_i) &= \frac{p(y=1\vert \vec{x}_i, \vec{\theta}_i)}{p(y=0\vert \vec{x}_i, \vec{\theta}_i) + p(y=1\vert \vec{x}_i, \vec{\theta}_i)} \\
&= \frac{p(\vec{x}_i, \vec{\theta}_i \vert y=1)p(y=1)/p(\vec{x}_i, \vec{\theta}_i)}{p(\vec{x}_i, \vec{\theta}_i\vert y=0)p(y=0)/p(\vec{x}_i, \vec{\theta}_i) + p(\vec{x}_i, \vec{\theta}_i\vert y=1)p(y=1)/p(\vec{x}_i, \vec{\theta}_i)} \\
&= \frac{p(\vec{x}_i, \vec{\theta}_i \vert y=1)p(y=1)}{p(\vec{x}_i, \vec{\theta}_i\vert y=0)p(y=0) + p(\vec{x}_i, \vec{\theta}_i\vert y=1)p(y=1)} \\
&= \frac{p(\vec{x}_i, \vec{\theta}_i \vert y=1)}{p(\vec{x}_i, \vec{\theta}_i\vert y=0) + p(\vec{x}_i, \vec{\theta}_i\vert y=1)} \\
\end{align}$$

Then by constructing we know that,

$$\begin{align}
p(\vec{x}_i, \vec{\theta}_i \vert y=1) &= p(\vec{x}_i, \vec{\theta}_i) \\
p(\vec{x}_i, \vec{\theta}_i \vert y=0) &= p(\vec{x}_i)p(\vec{\theta}_i).
\end{align}$$


So, 

$$\begin{align}
f_\varphi(\vec{x}_i, \vec{\theta}_i) &= \frac{p(\vec{x}_i, \vec{\theta}_i \vert y=1)}{p(\vec{x}_i, \vec{\theta}_i\vert y=0) + p(\vec{x}_i, \vec{\theta}_i\vert y=1)} \\
&= \frac{p(\vec{x}_i, \vec{\theta}_i)}{p(\vec{x}_i)p(\vec{\theta}_i) + p(\vec{x}_i, \vec{\theta}_i)}. \\
\end{align}$$


At this point you might be thinking "whoop-di-doo", well with one further slight manipulation you can see the benefit.


$$\begin{align}
r_\varphi(\vec{x}_i, \vec{\theta}_i) &= \frac{f_\varphi(\vec{x}_i, \vec{\theta}_i)}{1-f_\varphi(\vec{x}_i, \vec{\theta}_i)} \\

&= \frac{\frac{p(\vec{x}_i, \vec{\theta}_i)}{p(\vec{x}_i)p(\vec{\theta}_i) + p(\vec{x}_i, \vec{\theta}_i)}}{1-\frac{p(\vec{x}_i, \vec{\theta}_i)}{p(\vec{x}_i)p(\vec{\theta}_i) + p(\vec{x}_i, \vec{\theta}_i)}}\\


&= \frac{p(\vec{x}_i, \vec{\theta}_i)}{p(\vec{x}_i)p(\vec{\theta}_i) + p(\vec{x}_i, \vec{\theta}_i) - p(\vec{x}_i, \vec{\theta}_i)}\\


&= \frac{p(\vec{x}_i, \vec{\theta}_i)}{p(\vec{x}_i)p(\vec{\theta}_i)}\\


&= \frac{p(\vec{x}_i\vert \vec{\theta})}{p(\vec{x})}\\
\end{align}$$

The likelihood to evidence ratio, and we have the prior used to generate the simulations so by applying that you have a functional form of the posterior.

$$\begin{align}
r_\varphi(\vec{x}_i, \vec{\theta}_i) \cdot \pi(\vec{\theta}_i) &= \frac{p(\vec{x}_i\vert \vec{\theta})}{p(\vec{x})} \cdot \pi(\vec{\theta}_i) \\
&= p(\vec{\theta}_i\vert\vec{x}_i) \\
\end{align}$$


And $$\vec{x}_i$$ does not generally mean they are representing single data ponits, but sets of data corresponding to the hyper-parameters $$\vec{\theta}_i$$.

This setup has several benefits including and not limited to the reasons mentioned above and including and not limited to:
- you do not need a functional form of your likelihood (arguably the main reason and similar to the other methods) 
- you can construct a likelihood function with gradient support
- the constructed likelihood can be orders of magnitude cheaper to evaluate than an analytical one
- it seems really cool compared to MCMC (joke)


## A side note about using Sigmoid

Commonly the final layer of classifiers is a sigmoid function to make the output between 0 and 1,

$$\begin{align}
\sigma(x) = \frac{1}{1+e^-x} = \frac{e^x}{1+e^x} = 1-\sigma(-x).
\end{align}$$

What amazing about this, is if we chuck in we represent our network up to the final layer before a potential sigmoid as $$\ell$$ then our classifer can be expressed as,

$$\begin{align}
f_\varphi(\vec{x}_i, \vec{\theta}_i) = \frac{e^{\ell(\vec{x}_i, \vec{\theta}_i)}}{1+e^{\ell(\vec{x}_i, \vec{\theta}_i)}},
\end{align}$$

and our log-likelihood ratio (which we will later use in training),

$$\begin{align}
\log r_\varphi(\vec{x}_i, \vec{\theta}_i) &= \log \frac{f_\varphi(\vec{x}_i, \vec{\theta}_i) }{1-f_\varphi(\vec{x}_i, \vec{\theta}_i) } \\
&= \log \frac{\frac{e^{\ell(\vec{x}_i, \vec{\theta}_i)}}{1+e^{\ell(\vec{x}_i, \vec{\theta}_i)}} }{1-\frac{e^{\ell(\vec{x}_i, \vec{\theta}_i)}}{1+e^{\ell(\vec{x}_i, \vec{\theta}_i)}}} \\
&= \log \frac{\frac{e^{\ell(\vec{x}_i, \vec{\theta}_i)}}{1+e^{\ell(\vec{x}_i, \vec{\theta}_i)}} }{\frac{1+e^{\ell(\vec{x}_i, \vec{\theta}_i)} - e^{\ell(\vec{x}_i, \vec{\theta}_i)}}{1+e^{\ell(\vec{x}_i, \vec{\theta}_i)}}} \\
&= \log \frac{e^{\ell(\vec{x}_i, \vec{\theta}_i)}}{1+e^{\ell(\vec{x}_i, \vec{\theta}_i)} - e^{\ell(\vec{x}_i, \vec{\theta}_i)}} \\
&= \log e^{\ell(\vec{x}_i, \vec{\theta}_i)} \\
&= \ell(\vec{x}_i, \vec{\theta}_i) \\
\end{align}$$



<div style="text-align: center;">
<img 
    src="https://tenor.com/en-GB/view/wut-whaaaa-wtf-gif-13435564428279031829.gif" 
    alt="Me after seeing log r = l"
    title="Me after seeing log r = l"
    style="width: 50%; height: auto; border-radius: 32px;">
</div>

<br>

i.e. The logit in the final layer of the classifier _is_ our log-likelihood ratio. This, and the fact that naive implements of the sigmoid can cause vanishing gradients/numerical instabilities, motivates us to not have this activation at the end of our network but instead migrate it into the loss. So that we can train the classifier as a classifier but then very easily use it as a log-likelihood ratio!

<br>

# Rudimentary Implementations

Similar to [my previous post](https://liamcpinchbeck.github.io/posts/2025/08/2025-08-11-SBI-w-NPE-NLE/) we can make the dependencies in the above expression $$\vec{x}$$ single data points (as was expressed for the [NLE](https://liamcpinchbeck.github.io/posts/2025/08/2025-08-11-SBI-w-NPE-NLE/#:~:text=neural%20likelihood%20estimation.-,Neural%20Likelihood%20Estimation,-In%20neural%20likelihood)) or for an entire dataset (as was done for [NPE](https://liamcpinchbeck.github.io/posts/2025/08/2025-08-11-SBI-w-NPE-NLE/#:~:text=Estimation%20or%20NPE.-,Neural%20Posterior%20Estimation%20(NPE),-Continuing%20off%20from)). Unlike for those methods, I will show implementations for the per-event likelihood ___and___ the dataset level likelihood.

## Binary Classifier Network

Before I get into the specifics we will first construct our Binary Classifier Network, as it will be the same for both approaches (the differences will be in how we handle the data in _embedding_). We'll leave the number of hidden nodes free and use three hidden layers and leave the dimensionality of the input free for now as well.

```python
import torch.nn as nn
import torch.nn.functional as F

class BinaryNet(nn.Module):
    def __init__(self, input_dim, hidden_nodes=32):
        super().__init__()
        self.fc_in = nn.Linear(input_dim, hidden_nodes) 

        self.fc1 = nn.Linear(hidden_nodes, hidden_nodes)
        self.fc2 = nn.Linear(hidden_nodes, hidden_nodes)
        self.fc3 = nn.Linear(hidden_nodes, hidden_nodes)

        self.fc_out = nn.Linear(hidden_nodes, 1)


    def forward(self, x):
        y = F.relu(self.fc_in(x))

        y = F.relu(self.fc1(y))
        y = F.relu(self.fc2(y))
        y = F.relu(self.fc3(y))

        # no sigmoid or softmax here!
        return self.fc_out(y)
```

And I would like to emphasize that the "$$y$$"s and "$$x$$"s in the code do not necessarily map to anything in the math, its purely to denote 'input' and 'output'.


## Per Event Rudimentary Implementation








<br>



## Dataset Level Rudimentary Implementation






<br>


# Conclusion





<br>
---
---